{
  "task_type": "llm",
  "input_dim": 512,
  "hidden_dim": 512,
  "output_dim": 32000,
  "liquid_units": 192,
  "liquid_backbone": "ncp",
  "spiking_units": 96,
  "spike_threshold": 1.2,
  "beta": 0.92,
  "num_spike_steps": 28,
  "num_layers": 10,
  "num_attention_heads": 8,
  "embedding_dim": 512,
  "max_position_embeddings": 2048,
  "vocab_size": 32000,
  "conv_channels": null,
  "conv_kernel_sizes": null,
  "conv_strides": null,
  "conv_padding": null,
  "dropout": 0.12,
  "attention_dropout": 0.12,
  "embedding_dropout": 0.12,
  "sequence_length": 1024,
  "batch_size": 4,
  "learning_rate": 0.00025,
  "weight_decay": 0.015,
  "gradient_clip": 1.2,
  "mixed_precision": true,
  "device": "cuda",
  "seed": 456,
  "num_epochs": 18,
  "layer_norm_eps": 1e-05,
  "initializer_range": 0.02,
  "use_cache": true
}