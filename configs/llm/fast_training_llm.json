{
  "task_type": "llm",
  "input_dim": 384,
  "hidden_dim": 384,
  "output_dim": 50257,
  "liquid_units": 96,
  "liquid_backbone": "cfc",
  "spiking_units": 48,
  "spike_threshold": 0.7,
  "beta": 0.98,
  "num_spike_steps": 20,
  "num_layers": 8,
  "num_attention_heads": 6,
  "embedding_dim": 384,
  "max_position_embeddings": 512,
  "vocab_size": 50257,
  "conv_channels": null,
  "conv_kernel_sizes": null,
  "conv_strides": null,
  "conv_padding": null,
  "dropout": 0.05,
  "attention_dropout": 0.05,
  "embedding_dropout": 0.05,
  "sequence_length": 256,
  "batch_size": 12,
  "learning_rate": 0.0008,
  "weight_decay": 0.005,
  "gradient_clip": 0.8,
  "mixed_precision": true,
  "device": "cuda",
  "seed": 789,
  "num_epochs": 8,
  "layer_norm_eps": 1e-05,
  "initializer_range": 0.02,
  "use_cache": true
}